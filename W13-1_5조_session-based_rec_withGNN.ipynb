{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# data 준비하기"
      ],
      "metadata": {
        "id": "EFAs6oPj3ejp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import operator\n",
        "import pickle\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bTR5cNFl7JQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download data"
      ],
      "metadata": {
        "id": "UPd1ywKR3iIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMIPyZ6_2Zuv",
        "outputId": "27e33d35-fdc1-4db9-a3f1-ff6f52793631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yx7C701EnMs9phbJr2cnzg_yx8Tr0t--\n",
            "To: /content/sr_gnn_sample.csv\n",
            "\r  0% 0.00/395k [00:00<?, ?B/s]\r100% 395k/395k [00:00<00:00, 111MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1Yx7C701EnMs9phbJr2cnzg_yx8Tr0t--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_raw = pd.read_csv('./sr_gnn_sample.csv')\n",
        "sample_raw.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Y9RVtpA92m9_",
        "outputId": "970358f1-5825-4009-e668-6a29222b9e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id;user_id;item_id;timeframe;eventdate\n",
              "0                    1;NA;81766;526309;2016-05-09\n",
              "1                   1;NA;31331;1031018;2016-05-09\n",
              "2                    1;NA;32118;243569;2016-05-09\n",
              "3                      1;NA;9654;75848;2016-05-09\n",
              "4                   1;NA;32627;1112408;2016-05-09\n",
              "5                    1;NA;33043;173912;2016-05-09\n",
              "6                    1;NA;12352;329870;2016-05-09\n",
              "7                    1;NA;35077;390072;2016-05-09\n",
              "8                    1;NA;36118;487369;2016-05-09\n",
              "9                   1;NA;129055;991416;2016-05-09\n",
              "10                    2;NA;3147;883039;2016-05-09\n",
              "11                   2;NA;32754;359839;2016-05-09\n",
              "12                   2;NA;100747;38317;2016-05-09\n",
              "13                   2;NA;32971;182759;2016-05-09\n",
              "14                   2;NA;10657;387340;2016-05-09\n",
              "15                   2;NA;35606;756335;2016-05-09\n",
              "16                    2;NA;35606;53684;2016-05-09\n",
              "17                   2;NA;36246;332000;2016-05-09\n",
              "18                   2;NA;36246;722492;2016-05-09\n",
              "19                 2;NA;196110;1045018;2016-05-09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1999731a-c64b-4ae7-a18f-5f53361343d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id;user_id;item_id;timeframe;eventdate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1;NA;81766;526309;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;NA;31331;1031018;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1;NA;32118;243569;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1;NA;9654;75848;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1;NA;32627;1112408;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;NA;33043;173912;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1;NA;12352;329870;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1;NA;35077;390072;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1;NA;36118;487369;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;NA;129055;991416;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2;NA;3147;883039;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2;NA;32754;359839;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2;NA;100747;38317;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2;NA;32971;182759;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2;NA;10657;387340;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2;NA;35606;756335;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2;NA;35606;53684;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2;NA;36246;332000;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2;NA;36246;722492;2016-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2;NA;196110;1045018;2016-05-09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1999731a-c64b-4ae7-a18f-5f53361343d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1999731a-c64b-4ae7-a18f-5f53361343d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1999731a-c64b-4ae7-a18f-5f53361343d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74a8bd98-b9dc-488c-91d6-8390bb979cbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74a8bd98-b9dc-488c-91d6-8390bb979cbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74a8bd98-b9dc-488c-91d6-8390bb979cbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocess data"
      ],
      "metadata": {
        "id": "MIgbK0zk3lm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = './sr_gnn_sample.csv'\n",
        "\n",
        "print(\"-- Starting @ %ss\" % datetime.datetime.now())\n",
        "with open(dataset, \"r\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=';')\n",
        "    sess_clicks = {}\n",
        "    sess_date = {}\n",
        "    ctr = 0\n",
        "    curid = -1\n",
        "    curdate = None\n",
        "    for data in reader:\n",
        "        sessid = data['session_id']\n",
        "        if curdate and not curid == sessid:\n",
        "            date = ''\n",
        "            date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "            sess_date[curid] = date\n",
        "        curid = sessid\n",
        "        item = data['item_id'], int(data['timeframe'])\n",
        "        curdate = ''\n",
        "        curdate = data['eventdate']\n",
        "\n",
        "        if sessid in sess_clicks:\n",
        "            sess_clicks[sessid] += [item]\n",
        "        else:\n",
        "            sess_clicks[sessid] = [item]\n",
        "        ctr += 1\n",
        "    date = ''\n",
        "    date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "    for i in list(sess_clicks):\n",
        "        sorted_clicks = sorted(sess_clicks[i], key=operator.itemgetter(1))\n",
        "        sess_clicks[i] = [c[0] for c in sorted_clicks]\n",
        "    sess_date[curid] = date\n",
        "print(\"-- Reading data @ %ss\" % datetime.datetime.now())\n",
        "\n",
        "# Filter out length 1 sessions\n",
        "for s in list(sess_clicks):\n",
        "    if len(sess_clicks[s]) == 1:\n",
        "        del sess_clicks[s]\n",
        "        del sess_date[s]\n",
        "\n",
        "# Count number of times each item appears\n",
        "iid_counts = {}\n",
        "for s in sess_clicks:\n",
        "    seq = sess_clicks[s]\n",
        "    for iid in seq:\n",
        "        if iid in iid_counts:\n",
        "            iid_counts[iid] += 1\n",
        "        else:\n",
        "            iid_counts[iid] = 1\n",
        "\n",
        "sorted_counts = sorted(iid_counts.items(), key=operator.itemgetter(1))\n",
        "\n",
        "length = len(sess_clicks)\n",
        "for s in list(sess_clicks):\n",
        "    curseq = sess_clicks[s]\n",
        "    filseq = list(filter(lambda i: iid_counts[i] >= 5, curseq))\n",
        "    if len(filseq) < 2:\n",
        "        del sess_clicks[s]\n",
        "        del sess_date[s]\n",
        "    else:\n",
        "        sess_clicks[s] = filseq\n",
        "\n",
        "# Split out test set based on dates\n",
        "dates = list(sess_date.items())\n",
        "maxdate = dates[0][1]\n",
        "\n",
        "for _, date in dates:\n",
        "    if maxdate < date:\n",
        "        maxdate = date\n",
        "\n",
        "# 7 days for test\n",
        "splitdate = maxdate - 86400 * 7\n",
        "\n",
        "print('Splitting date', splitdate)\n",
        "tra_sess = filter(lambda x: x[1] < splitdate, dates)\n",
        "tes_sess = filter(lambda x: x[1] > splitdate, dates)\n",
        "\n",
        "# Sort sessions by date\n",
        "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))     # [(session_id, timestamp), (), ]\n",
        "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))     # [(session_id, timestamp), (), ]\n",
        "print(len(tra_sess))    # 186670    # 7966257\n",
        "print(len(tes_sess))    # 15979     # 15324\n",
        "print(tra_sess[:3])\n",
        "print(tes_sess[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNS-kM7i3ALe",
        "outputId": "f6f0e38b-986f-407b-82d5-748c1f50dd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Starting @ 2023-11-30 10:57:38.295614s\n",
            "-- Reading data @ 2023-11-30 10:57:38.387347s\n",
            "Splitting date 1464134400.0\n",
            "469\n",
            "47\n",
            "[('2671', 1451952000.0), ('1211', 1452384000.0), ('3780', 1452384000.0)]\n",
            "[('1864', 1464220800.0), ('1867', 1464220800.0), ('1868', 1464220800.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Choosing item count >=5 gives approximately the same number of items as reported in paper\n",
        "item_dict = {}\n",
        "# Convert training sessions to sequences and renumber items to start from 1\n",
        "def obtian_tra():\n",
        "    train_ids = []\n",
        "    train_seqs = []\n",
        "    train_dates = []\n",
        "    item_ctr = 1\n",
        "    for s, date in tra_sess:\n",
        "        seq = sess_clicks[s]\n",
        "        outseq = []\n",
        "        for i in seq:\n",
        "            if i in item_dict:\n",
        "                outseq += [item_dict[i]]\n",
        "            else:\n",
        "                outseq += [item_ctr]\n",
        "                item_dict[i] = item_ctr\n",
        "                item_ctr += 1\n",
        "        if len(outseq) < 2:  # Doesn't occur\n",
        "            continue\n",
        "        train_ids += [s]\n",
        "        train_dates += [date]\n",
        "        train_seqs += [outseq]\n",
        "    print(item_ctr)     # 43098, 37484\n",
        "    return train_ids, train_dates, train_seqs\n",
        "\n",
        "\n",
        "# Convert test sessions to sequences, ignoring items that do not appear in training set\n",
        "def obtian_tes():\n",
        "    test_ids = []\n",
        "    test_seqs = []\n",
        "    test_dates = []\n",
        "    for s, date in tes_sess:\n",
        "        seq = sess_clicks[s]\n",
        "        outseq = []\n",
        "        for i in seq:\n",
        "            if i in item_dict:\n",
        "                outseq += [item_dict[i]]\n",
        "        if len(outseq) < 2:\n",
        "            continue\n",
        "        test_ids += [s]\n",
        "        test_dates += [date]\n",
        "        test_seqs += [outseq]\n",
        "    return test_ids, test_dates, test_seqs\n",
        "\n",
        "\n",
        "tra_ids, tra_dates, tra_seqs = obtian_tra()\n",
        "tes_ids, tes_dates, tes_seqs = obtian_tes()\n",
        "\n",
        "\n",
        "def process_seqs(iseqs, idates):\n",
        "    out_seqs = []\n",
        "    out_dates = []\n",
        "    labs = []\n",
        "    ids = []\n",
        "    for id, seq, date in zip(range(len(iseqs)), iseqs, idates):\n",
        "        for i in range(1, len(seq)):\n",
        "            tar = seq[-i]\n",
        "            labs += [tar]\n",
        "            out_seqs += [seq[:-i]]\n",
        "            out_dates += [date]\n",
        "            ids += [id]\n",
        "    return out_seqs, out_dates, labs, ids\n",
        "\n",
        "\n",
        "tr_seqs, tr_dates, tr_labs, tr_ids = process_seqs(tra_seqs, tra_dates)\n",
        "te_seqs, te_dates, te_labs, te_ids = process_seqs(tes_seqs, tes_dates)\n",
        "tra = (tr_seqs, tr_labs)\n",
        "tes = (te_seqs, te_labs)\n",
        "print(len(tr_seqs))\n",
        "print(len(te_seqs))\n",
        "print(tr_seqs[:3], tr_dates[:3], tr_labs[:3])\n",
        "print(te_seqs[:3], te_dates[:3], te_labs[:3])\n",
        "all = 0\n",
        "\n",
        "for seq in tra_seqs:\n",
        "    all += len(seq)\n",
        "for seq in tes_seqs:\n",
        "    all += len(seq)\n",
        "print('avg length: ', all/(len(tra_seqs) + len(tes_seqs) * 1.0))\n",
        "\n",
        "if not os.path.exists('sample'):\n",
        "    os.makedirs('sample')\n",
        "\n",
        "pickle.dump(tra, open('sample/train.txt', 'wb'))\n",
        "pickle.dump(tes, open('sample/test.txt', 'wb'))\n",
        "pickle.dump(tra_seqs, open('sample/all_train_seq.txt', 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFuvbJ4m2cC",
        "outputId": "a5056d63-6712-44a9-d45e-22a0d69698d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310\n",
            "1205\n",
            "99\n",
            "[[1, 2], [1], [4]] [1451952000.0, 1451952000.0, 1452384000.0] [3, 2, 5]\n",
            "[[282], [281, 308], [281]] [1464220800.0, 1464220800.0, 1464220800.0] [282, 281, 308]\n",
            "avg length:  3.5669291338582676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# util functions"
      ],
      "metadata": {
        "id": "XapGl0Q-37vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_masks(all_usr_pois, item_tail): # padding 작업을 수행하는 코드\n",
        "    us_lens = [len(upois) for upois in all_usr_pois]\n",
        "    len_max = max(us_lens)\n",
        "    us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
        "    us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
        "    return us_pois, us_msks, len_max\n",
        "\n",
        "\n",
        "def split_validation(train_set, valid_portion):\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)\n",
        "\n",
        "def trans_to_cuda(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cuda()\n",
        "    else:\n",
        "        return variable\n",
        "\n",
        "def trans_to_cpu(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cpu()\n",
        "    else:\n",
        "        return variable"
      ],
      "metadata": {
        "id": "J6CXsEXR3o7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data class"
      ],
      "metadata": {
        "id": "NiTJcIqM4Bpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data():\n",
        "    def __init__(self, data, shuffle=False):\n",
        "        inputs = data[0] # * inputs : [[4, 5, 7, 8,], [1, 3, 7], ...] 같은 구조\n",
        "\n",
        "        # * mask : [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0], ...] 같은 구조\n",
        "        # * data_masks function을 보면 알겠지만, 제일 긴 sequence 하나 잡고, 그거를 기준으로 패딩해주는 거임\n",
        "        # * inputs랑 아래 inputs의 차이는 padding 여부\n",
        "        # * EX. inputs : [[4, 5, 7, 8,], [1, 3, 7], ...] --변환--> inputs : [[4, 5, 7, 8, 0, 0, 0, 0, ...], ...]\n",
        "        inputs, mask, len_max = data_masks(inputs, [0])\n",
        "\n",
        "        self.inputs = np.asarray(inputs)\n",
        "        self.mask = np.asarray(mask)\n",
        "        self.len_max = len_max\n",
        "        self.targets = np.asarray(data[1])\n",
        "        self.length = len(inputs)\n",
        "        self.shuffle = shuffle # * boolean\n",
        "\n",
        "\n",
        "    def generate_batch(self, batch_size):\n",
        "        if self.shuffle:\n",
        "            shuffled_arg = np.arange(self.length)\n",
        "            np.random.shuffle(shuffled_arg)\n",
        "            self.inputs = self.inputs[shuffled_arg]\n",
        "            self.mask = self.mask[shuffled_arg]\n",
        "            self.targets = self.targets[shuffled_arg]\n",
        "        n_batch = int(self.length / batch_size)  # batch_size : 4, self.length : 10 이면, n_batch : 2\n",
        "        if self.length % batch_size != 0:\n",
        "            n_batch += 1 # n_batch : 3\n",
        "        slices = np.split(np.arange(n_batch * batch_size), n_batch) # slices : [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]\n",
        "        slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))] # slices : [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9]]\n",
        "        # [8, 9] = [8, 9][:10 - 4 * (3 - 1)] = [8, 9][:2] = [8, 9]\n",
        "\n",
        "        # * Suppose self.length = 10 and batch_size = 3.\n",
        "        # * Number of batches (n_batch) would be 4 (three batches of 3 and one batch of 1).\n",
        "        # * slices would be an array of index arrays: [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]].\n",
        "        return slices\n",
        "\n",
        "    def get_slice(self, slice):\n",
        "        # * i : [0, 1, 2, 3] 같은 구조\n",
        "\n",
        "        inputs, mask, targets = self.inputs[slice], self.mask[slice], self.targets[slice]\n",
        "        items, n_node, A, alias_inputs = [], [], [], []\n",
        "\n",
        "        # * n_node는 각 sequence의 unique한 item 갯수를 의미함.\n",
        "        # * 결과적으로 제일 긴 node 가지고 padding 해주려고 그럼.\n",
        "        for u_input in inputs:\n",
        "            n_node.append(len(np.unique(u_input)))\n",
        "        max_n_node = np.max(n_node)\n",
        "\n",
        "        for u_input in inputs:\n",
        "            node = np.unique(u_input)\n",
        "\n",
        "            # * items : [[4, 5, 7, 8, 0, 0, 0, 0, ...], ...] 같은 구조 (sequence 아님, node 들임)\n",
        "            items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
        "\n",
        "            # * 아래 코드는 max unique sequence (session) 을 기준으로 커다란 Adjacency matrix를 만들고,\n",
        "            # * EX. 제일 긴 seq이 10개 item이었으면, 10x10짜리 adj matrix를 만들어서, 각각의 sequence에 대해\n",
        "\n",
        "            u_A = np.zeros((max_n_node, max_n_node))\n",
        "            for slice in np.arange(len(u_input) - 1):\n",
        "                if u_input[slice + 1] == 0:\n",
        "                    # padding 나오면 break\n",
        "                    break\n",
        "                # node [4, 5, 7, 8]\n",
        "                # [4, 5, 7, 8, 0, 0, 0, ]\n",
        "\n",
        "                # [4, 5, 7, 4, 8] 에서 [4] [True, False, False, True, False]\n",
        "                u = np.where(node == u_input[slice])[0][0]\n",
        "                v = np.where(node == u_input[slice + 1])[0][0]\n",
        "                u_A[u][v] = 1\n",
        "\n",
        "            u_sum_in = np.sum(u_A, 0)\n",
        "            u_sum_in[np.where(u_sum_in == 0)] = 1\n",
        "            u_A_in = np.divide(u_A, u_sum_in) # normalize adj matrix\n",
        "            u_sum_out = np.sum(u_A, 1)\n",
        "            u_sum_out[np.where(u_sum_out == 0)] = 1\n",
        "            u_A_out = np.divide(u_A.transpose(), u_sum_out) # normalize adj matrix\n",
        "            u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
        "            A.append(u_A)\n",
        "\n",
        "            alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
        "            # * alias inputs는 각 sequence의 item들이 unique한 index를 가지고 있음.\n",
        "\n",
        "        # * 결과적으로,\n",
        "        return alias_inputs, A, items, mask, targets"
      ],
      "metadata": {
        "id": "zG5-isiK3_2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## return 값 구경하기"
      ],
      "metadata": {
        "id": "G3kqHiI84jAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = pickle.load(open('./sample/train.txt', 'rb'))\n",
        "train_data = Data(train_data, shuffle=False)\n",
        "\n",
        "print('inputs\\n', train_data.inputs)\n",
        "print('target\\n', train_data.targets)\n",
        "\n",
        "slices= [[43, 44, 45, 46]]\n",
        "print('\\n\\ntrain_data\\n', train_data.inputs[slices[0]])\n",
        "print('target_data\\n', train_data.targets[slices[0]])\n",
        "\n",
        "\n",
        "for i, j in zip(slices, np.arange(len(slices))):\n",
        "    alias_inputs, A, items, mask, targets = train_data.get_slice(i)\n",
        "    print('\\n\\ni\\n', i)\n",
        "    print('\\n\\nalias_inputs\\n', alias_inputs)\n",
        "    print('\\n\\nA\\n', A)\n",
        "    print('\\n\\nitems\\n', items)\n",
        "    print('\\n\\nmask\\n', mask)\n",
        "    print('\\n\\ntargets\\n', targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6FUU4cx4mHk",
        "outputId": "5d72f051-8f64-4f07-9871-ddb1ff9c6338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            " [[  1   2   0 ...   0   0   0]\n",
            " [  1   0   0 ...   0   0   0]\n",
            " [  4   0   0 ...   0   0   0]\n",
            " ...\n",
            " [272 287 287 ...   0   0   0]\n",
            " [272 287   0 ...   0   0   0]\n",
            " [272   0   0 ...   0   0   0]]\n",
            "target\n",
            " [  3   2   5 ... 287 287 287]\n",
            "\n",
            "\n",
            "train_data\n",
            " [[12 13 12 13 35 35 12 13  0  0  0  0  0  0  0  0]\n",
            " [12 13 12 13 35 35 12  0  0  0  0  0  0  0  0  0]\n",
            " [12 13 12 13 35 35  0  0  0  0  0  0  0  0  0  0]\n",
            " [12 13 12 13 35  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "target_data\n",
            " [12 13 12 35]\n",
            "\n",
            "\n",
            "i\n",
            " [43, 44, 45, 46]\n",
            "\n",
            "\n",
            "alias_inputs\n",
            " [[1, 2, 1, 2, 3, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 1, 2, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 1, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "\n",
            "A\n",
            " [array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
            "       [0. , 0. , 0.5, 0.5, 0. , 0. , 1. , 0. ],\n",
            "       [0. , 1. , 0. , 0. , 0. , 0.5, 0. , 0.5],\n",
            "       [0. , 0. , 0.5, 0.5, 0. , 0.5, 0. , 0.5]]), array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
            "       [0. , 0. , 0.5, 0.5, 0. , 0. , 1. , 0. ],\n",
            "       [0. , 1. , 0. , 0. , 0. , 0.5, 0. , 0.5],\n",
            "       [0. , 0. , 0.5, 0.5, 0. , 0.5, 0. , 0.5]]), array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
            "       [0. , 0. , 1. , 0. , 0. , 0. , 1. , 0. ],\n",
            "       [0. , 1. , 0. , 0. , 0. , 0.5, 0. , 0.5],\n",
            "       [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 1. ]]), array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
            "       [0. , 0. , 1. , 0. , 0. , 0. , 1. , 0. ],\n",
            "       [0. , 1. , 0. , 0. , 0. , 0.5, 0. , 0.5],\n",
            "       [0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. ]])]\n",
            "\n",
            "\n",
            "items\n",
            " [[0, 12, 13, 35], [0, 12, 13, 35], [0, 12, 13, 35], [0, 12, 13, 35]]\n",
            "\n",
            "\n",
            "mask\n",
            " [[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "\n",
            "targets\n",
            " [12 13 12 35]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "hEr8GXG54WBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Module, Parameter\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "NIh_LibG4azW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(Module):\n",
        "    def __init__(self, hidden_size, step=1):\n",
        "        super(GNN, self).__init__()\n",
        "        self.step = step\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = hidden_size * 2\n",
        "        self.gate_size = 3 * hidden_size\n",
        "        self.w_ih = Parameter(torch.Tensor(self.gate_size, self.input_size))\n",
        "        self.w_hh = Parameter(torch.Tensor(self.gate_size, self.hidden_size))\n",
        "        self.b_ih = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_hh = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_iah = Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.b_oah = Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        self.linear_edge_in = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_edge_out = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        # self.linear_edge_f = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "\n",
        "    def GNNCell(self, A, hidden):\n",
        "        input_in = torch.matmul(A[:, :, :A.shape[1]], self.linear_edge_in(hidden)) + self.b_iah\n",
        "        input_out = torch.matmul(A[:, :, A.shape[1]: 2 * A.shape[1]], self.linear_edge_out(hidden)) + self.b_oah\n",
        "        inputs = torch.cat([input_in, input_out], 2)\n",
        "\n",
        "        gi = F.linear(inputs, self.w_ih, self.b_ih)\n",
        "        gh = F.linear(hidden, self.w_hh, self.b_hh)\n",
        "\n",
        "        i_r, i_i, i_n = gi.chunk(3, 2)\n",
        "        h_r, h_i, h_n = gh.chunk(3, 2)\n",
        "\n",
        "        resetgate = torch.sigmoid(i_r + h_r) # reset gate\n",
        "        inputgate = torch.sigmoid(i_i + h_i) # update gate\n",
        "\n",
        "        newgate = torch.tanh(i_n + resetgate * h_n) # candidate date\n",
        "\n",
        "        hy = newgate + inputgate * (hidden - newgate)\n",
        "\n",
        "        return hy\n",
        "\n",
        "    def forward(self, A, hidden):\n",
        "        for i in range(self.step):\n",
        "            hidden = self.GNNCell(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class SessionGraph(Module):\n",
        "    def __init__(self,\n",
        "                 n_node,\n",
        "                 hiddenSize,\n",
        "                 batchSize,\n",
        "                 nonhybrid,\n",
        "                 step,\n",
        "                 lr,\n",
        "                 l2,\n",
        "                 lr_dc_step,\n",
        "                 lr_dc\n",
        "                 ):\n",
        "        super(SessionGraph, self).__init__()\n",
        "        self.n_node = n_node\n",
        "        self.hidden_size = hiddenSize\n",
        "        self.batch_size = batchSize\n",
        "        self.nonhybrid = nonhybrid\n",
        "        self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
        "        self.gnn = GNN(self.hidden_size, step=step)\n",
        "\n",
        "        self.linear_transform = nn.Linear(self.hidden_size * 2, self.hidden_size, bias=True)\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=lr_dc_step, gamma=lr_dc)\n",
        "        self.reset_parameters()\n",
        "\n",
        "        self.linear_one = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_two = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_three = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def compute_scores(self, hidden, mask):\n",
        "        ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
        "\n",
        "        q1 = self.linear_one(ht).view(ht.shape[0], 1, ht.shape[1])  # batch_size x 1 x latent_size\n",
        "        q2 = self.linear_two(hidden)  # batch_size x seq_length x latent_size\n",
        "        alpha = self.linear_three(torch.sigmoid(q1 + q2))\n",
        "        a = torch.sum(alpha * hidden * mask.view(mask.shape[0], -1, 1).float(), 1)\n",
        "\n",
        "        if not self.nonhybrid:\n",
        "            a = self.linear_transform(torch.cat([a, ht], 1))\n",
        "\n",
        "        b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
        "\n",
        "        scores = torch.matmul(a, b.transpose(1, 0)) # score\n",
        "        return scores\n",
        "\n",
        "    def forward(self, inputs, A):\n",
        "        hidden = self.embedding(inputs)\n",
        "        hidden = self.gnn(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "\n",
        "def forward(model, i, data):\n",
        "    # * model is SessionGraph instance\n",
        "    alias_inputs, A, items, mask, targets = data.get_slice(i) # batch별로 필요한 데이터 생성 - Data.get_slice() 함수 확인\n",
        "    alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
        "    items = trans_to_cuda(torch.Tensor(items).long())\n",
        "    A = trans_to_cuda(torch.Tensor(A).float())\n",
        "    mask = trans_to_cuda(torch.Tensor(mask).long())\n",
        "\n",
        "    hidden = model(items, A)\n",
        "    get = lambda i: hidden[i][alias_inputs[i]]\n",
        "    seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
        "    return targets, model.compute_scores(seq_hidden, mask)\n",
        "\n",
        "\n",
        "def train_test(model, train_data, test_data):\n",
        "    # * model is SessionGraph instance\n",
        "    model.scheduler.step()\n",
        "    print('start training: ', datetime.datetime.now())\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    slices = train_data.generate_batch(model.batch_size) # session seq --batch--> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]].\n",
        "    for i, j in zip(slices, np.arange(len(slices))):\n",
        "        model.optimizer.zero_grad()\n",
        "        targets, scores = forward(model, i, train_data)\n",
        "        targets = trans_to_cuda(torch.Tensor(targets).long())\n",
        "        loss = model.loss_function(scores, targets - 1)\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "        total_loss += loss\n",
        "        if j % int(len(slices) / 5 + 1) == 0:\n",
        "            print('[%d/%d] Loss: %.4f' % (j, len(slices), loss.item()))\n",
        "    print('\\tLoss:\\t%.3f' % total_loss)\n",
        "\n",
        "    print('start predicting: ', datetime.datetime.now())\n",
        "    model.eval()\n",
        "    hit, mrr = [], []\n",
        "    slices = test_data.generate_batch(model.batch_size)\n",
        "    for i in slices:\n",
        "        targets, scores = forward(model, i, test_data)\n",
        "        sub_scores = scores.topk(20)[1]\n",
        "        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
        "        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
        "            hit.append(np.isin(target - 1, score))\n",
        "            if len(np.where(score == target - 1)[0]) == 0:\n",
        "                mrr.append(0)\n",
        "            else:\n",
        "                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
        "    hit = np.mean(hit) * 100\n",
        "    mrr = np.mean(mrr) * 100\n",
        "    return hit, mrr"
      ],
      "metadata": {
        "id": "c3EGZSzS4Wwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train!"
      ],
      "metadata": {
        "id": "1vzhMbL95WXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyperparameters"
      ],
      "metadata": {
        "id": "9rghAuHk5xqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'sample'\n",
        "BATCH_SIZE = 100 # input batch size\n",
        "HIDDEN_SIZE = 400 # hidden state size\n",
        "EPOCH = 10 # the number of epochs to train for\n",
        "LR = 0.001 # learning rate [0.001, 0.0005, 0.0001]\n",
        "LR_DC = 0.1 # learning rate decay rate\n",
        "LR_DC_STEP = 3 # the number of steps after which the learning rate decay\n",
        "L2 = 1e-5 # l2 penalty [0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
        "STEP = 1 # gnn propogation steps\n",
        "PATIENCE = 10 # the number of epoch to wait before early stop\n",
        "NO_NHYBRID = False # only use the global preference to predict\n",
        "VALIDATION = False # validation\n",
        "VALID_PORTION = 0.1 # split the portion of training set as validation set"
      ],
      "metadata": {
        "id": "tShLpVnB4YK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main function"
      ],
      "metadata": {
        "id": "8Cdvze2C51RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_data = pickle.load(open('./' + DATASET + '/train.txt', 'rb'))\n",
        "    if VALIDATION:\n",
        "        train_data, valid_data = split_validation(train_data, VALID_PORTION)\n",
        "        test_data = valid_data\n",
        "    else:\n",
        "        test_data = pickle.load(open('./' + DATASET + '/test.txt', 'rb'))\n",
        "\n",
        "    train_data = Data(train_data, shuffle=True) ## Data class 살펴보기\n",
        "    test_data = Data(test_data, shuffle=False)\n",
        "\n",
        "    N_NODE = 310\n",
        "    model = trans_to_cuda(SessionGraph(N_NODE,\n",
        "                                       HIDDEN_SIZE,\n",
        "                                       BATCH_SIZE,\n",
        "                                       NO_NHYBRID,\n",
        "                                       STEP,\n",
        "                                       LR,\n",
        "                                       L2,\n",
        "                                       LR_DC_STEP,\n",
        "                                       LR_DC))  # Adjusted to use HIDDENSIZE directly\n",
        "\n",
        "    start = time.time()\n",
        "    best_result = [0, 0]\n",
        "    best_epoch = [0, 0]\n",
        "    bad_counter = 0\n",
        "    for epoch in range(EPOCH):\n",
        "        print('-------------------------------------------------------')\n",
        "        print('epoch: ', epoch)\n",
        "        hit, mrr = train_test(model, train_data, test_data)\n",
        "        flag = 0\n",
        "        if hit >= best_result[0]:\n",
        "            best_result[0] = hit\n",
        "            best_epoch[0] = epoch\n",
        "            flag = 1\n",
        "        if mrr >= best_result[1]:\n",
        "            best_result[1] = mrr\n",
        "            best_epoch[1] = epoch\n",
        "            flag = 1\n",
        "        print('Best Result:')\n",
        "        print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d,\\t%d' % (best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n",
        "        bad_counter += 1 - flag\n",
        "        if bad_counter >= PATIENCE:\n",
        "            break\n",
        "    print('-------------------------------------------------------')\n",
        "    end = time.time()\n",
        "    print(\"Run time: %f s\" % (end - start))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ot2l3tnk5oGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaG7yVqR55W7",
        "outputId": "c75a450a-8535-4fae-b29e-96181c45f3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2023-11-30 10:57:43.235038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-24-c69b13957523>:108: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  A = trans_to_cuda(torch.Tensor(A).float())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/13] Loss: 5.7342\n",
            "[3/13] Loss: 5.7312\n",
            "[6/13] Loss: 5.7170\n",
            "[9/13] Loss: 5.7201\n",
            "[12/13] Loss: 5.6853\n",
            "\tLoss:\t74.352\n",
            "start predicting:  2023-11-30 10:57:46.490246\n",
            "Best Result:\n",
            "\tRecall@20:\t2.0202\tMMR@20:\t0.3367\tEpoch:\t0,\t0\n",
            "-------------------------------------------------------\n",
            "epoch:  1\n",
            "start training:  2023-11-30 10:57:46.577874\n",
            "[0/13] Loss: 5.6580\n",
            "[3/13] Loss: 5.5956\n",
            "[6/13] Loss: 5.5351\n",
            "[9/13] Loss: 5.5909\n",
            "[12/13] Loss: 5.4351\n",
            "\tLoss:\t71.988\n",
            "start predicting:  2023-11-30 10:57:49.408983\n",
            "Best Result:\n",
            "\tRecall@20:\t5.0505\tMMR@20:\t0.5656\tEpoch:\t1,\t1\n",
            "-------------------------------------------------------\n",
            "epoch:  2\n",
            "start training:  2023-11-30 10:57:49.484624\n",
            "[0/13] Loss: 5.2638\n",
            "[3/13] Loss: 5.4098\n",
            "[6/13] Loss: 5.3033\n",
            "[9/13] Loss: 5.3198\n",
            "[12/13] Loss: 5.7981\n",
            "\tLoss:\t69.846\n",
            "start predicting:  2023-11-30 10:57:52.472775\n",
            "Best Result:\n",
            "\tRecall@20:\t5.0505\tMMR@20:\t0.6241\tEpoch:\t2,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  3\n",
            "start training:  2023-11-30 10:57:52.591413\n",
            "[0/13] Loss: 5.3813\n",
            "[3/13] Loss: 5.3461\n",
            "[6/13] Loss: 5.3173\n",
            "[9/13] Loss: 5.2196\n",
            "[12/13] Loss: 5.4581\n",
            "\tLoss:\t69.121\n",
            "start predicting:  2023-11-30 10:57:56.657831\n",
            "Best Result:\n",
            "\tRecall@20:\t5.0505\tMMR@20:\t0.6241\tEpoch:\t3,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  4\n",
            "start training:  2023-11-30 10:57:56.736686\n",
            "[0/13] Loss: 5.2553\n",
            "[3/13] Loss: 5.1730\n",
            "[6/13] Loss: 5.1630\n",
            "[9/13] Loss: 5.2932\n",
            "[12/13] Loss: 5.5180\n",
            "\tLoss:\t68.731\n",
            "start predicting:  2023-11-30 10:57:59.493533\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t4,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  5\n",
            "start training:  2023-11-30 10:57:59.569148\n",
            "[0/13] Loss: 5.4167\n",
            "[3/13] Loss: 5.1734\n",
            "[6/13] Loss: 5.2955\n",
            "[9/13] Loss: 5.1651\n",
            "[12/13] Loss: 5.7451\n",
            "\tLoss:\t68.636\n",
            "start predicting:  2023-11-30 10:58:02.326450\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t5,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  6\n",
            "start training:  2023-11-30 10:58:02.406078\n",
            "[0/13] Loss: 5.2332\n",
            "[3/13] Loss: 5.1880\n",
            "[6/13] Loss: 5.3232\n",
            "[9/13] Loss: 5.1350\n",
            "[12/13] Loss: 5.4944\n",
            "\tLoss:\t68.352\n",
            "start predicting:  2023-11-30 10:58:05.186627\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t6,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  7\n",
            "start training:  2023-11-30 10:58:05.267811\n",
            "[0/13] Loss: 5.1356\n",
            "[3/13] Loss: 5.2721\n",
            "[6/13] Loss: 5.3420\n",
            "[9/13] Loss: 5.1818\n",
            "[12/13] Loss: 4.4325\n",
            "\tLoss:\t67.296\n",
            "start predicting:  2023-11-30 10:58:08.969795\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t7,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  8\n",
            "start training:  2023-11-30 10:58:09.088855\n",
            "[0/13] Loss: 5.3110\n",
            "[3/13] Loss: 5.3222\n",
            "[6/13] Loss: 5.2631\n",
            "[9/13] Loss: 5.1839\n",
            "[12/13] Loss: 5.3628\n",
            "\tLoss:\t68.147\n",
            "start predicting:  2023-11-30 10:58:12.496193\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t8,\t2\n",
            "-------------------------------------------------------\n",
            "epoch:  9\n",
            "start training:  2023-11-30 10:58:12.576448\n",
            "[0/13] Loss: 5.2536\n",
            "[3/13] Loss: 5.2542\n",
            "[6/13] Loss: 5.2733\n",
            "[9/13] Loss: 5.2553\n",
            "[12/13] Loss: 5.5507\n",
            "\tLoss:\t68.321\n",
            "start predicting:  2023-11-30 10:58:15.364511\n",
            "Best Result:\n",
            "\tRecall@20:\t6.0606\tMMR@20:\t0.6241\tEpoch:\t9,\t2\n",
            "-------------------------------------------------------\n",
            "Run time: 32.214027 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEQ = 43\n",
        "\n",
        "_, _, seq, _, _ = train_data.get_slice([RANDOM_SEQ])\n",
        "print('sequence of item ids', seq)\n",
        "\n",
        "result = list(forward(model, [RANDOM_SEQ], train_data)[1].detach().numpy())\n",
        "print('result : ', np.argsort(result))\n",
        "print('true target : ', train_data.targets[RANDOM_SEQ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cENpWx9s551V",
        "outputId": "d13ba4e2-4b53-455b-e8ec-582378445c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence of item ids [[0, 12, 13, 35]]\n",
            "result :  [[ 79 298 236  44 112 100 297 229  50  82 288  88 159  75  38 166 134  63\n",
            "   99  98 216   0 283  31 256 164 271 155 306 209  14 213 114 154  19  40\n",
            "  143 190 121 272 251  87  57 211 188 130 169  20 245  25 238 175 255 220\n",
            "  300 101  35 285 244 262  83 219  45  41 167 237 264 162 243  70 123 109\n",
            "  144 280  37  89  90  91 205  78 214 257 147 126  80  73 265  48 108   8\n",
            "  249 276 137 122 118 199 152 228 181 294 202 274 182  16 185  59  81 110\n",
            "  161  36  21  15 270 153 232 241 148 128 290  39 165  29 173 273 192 135\n",
            "   71 218 116  61 102 132 248 291 156 124  56   7 193 207 168  10 204 296\n",
            "   95 189  74 179 303 269  58   1 307 176  49 197  96 195 145  66  32 278\n",
            "  284  47  94 171 212  13 250   9 186 191   5 275  86 146 234 210  64  24\n",
            "    4  18 131  46 138  97 282 299 113 292  17 286 174  53  92 125 129 177\n",
            "  223   2 231 261 157 217  85 230 158 301 117  28  68 163   3  54  67 127\n",
            "  119 170 263 106  27 246 208 107  93 133 240 105 136 235 305  30 215 115\n",
            "   52 194 308 120 140  51  62  43  72  33 151 242 266  77 180 196  76 247\n",
            "  225   6 302 104 287 281 178 203 160 221  26 279 184 111  11  42  69 226\n",
            "   84  22 200 293  65 150 172 227  60  12 187  55 139 304 254 268 224 260\n",
            "   23 259 258 183 239 198 267 149  34 103 289 277 295 233 252 222 253 141\n",
            "  142 201 206]]\n",
            "true target :  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7Q2JufRx8hD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}